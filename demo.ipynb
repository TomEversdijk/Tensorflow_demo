{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network, Keras & Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curriculum vitae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Achtergrond\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tom Eversdijk  \n",
    "Opleiding: Burgerlijk ingenieur computerwetenschappen - Artificiele intelligentie @KULeuven, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projecten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thesis: Intelligence trafficlights\n",
    "Ontwerpen van een systeem voor intelligente verkeerslichten dat de verkeersdoorstroming optimaliseert. Het doel was om te zorgen voor globale optimalisatie door rekening te houden met naburige kruispunten.\n",
    "\n",
    "NN: \n",
    "* input: wachttijd & aantal wachtende voertuigen per rijstrook voor een kruispunt [numeric] .\n",
    "* Output: Combinatie van verkeerslichten die gelijktijdig op groen gezet worden [0:1].\n",
    "* type: Deep neural network & Q-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Machine learning project: Dots & Boxes machine learning\n",
    "Ontwerpen van een AI die het spel [Dots & Boxes](https://nl.wikipedia.org/wiki/Kamertje_verhuren_(spel)) kan spelen.  \n",
    "\n",
    "NN:\n",
    "* input: Representatie van het speelbord [boolean]\n",
    "* output: Score voor bepaalde zet\n",
    "* Type: Deep Convolutional neural network getrained door self-play"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KULeuven DTAI: Connect 4 demo\n",
    "Bedenken, ontwerpen en ontwikkelen van een interactieve AI-demo ter promotie van departement computerwetenschappen specialisatie AI. Dit is gebeurd door een AI die het spel 4-op-een-rij kan spelen waarbij gebruikers de redenering van de AI kunnen bekijken en verschillende parameters kunnen instellen. Hier is gebruik gemaakt van Monte Carlo Tree Search (MCTS) & Deep Convolutional Neural\n",
    "\n",
    "Bevat een value & policy network, gelijkaardig aan [Alpha-Go](https://deepmind.com/research/case-studies/alphago-the-story-so-far)  \n",
    "\n",
    "Policy NN:\n",
    "* input: Representatie van het speelbord [-1;0;1]\n",
    "* output: Scores per mogelijk zet \n",
    "* Type: Deep Convolutional neural network getrained door self-play\n",
    "\n",
    "Value NN\n",
    "* input: Representatie van het speelbord [-1;0;1]\n",
    "* output: Waarschijnlijkheid van wins in de huidige situatie\n",
    "* Type: Deep Convolutional neural network getrained door MCTS plays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wat is een neuraal network?\n",
    "Een NN (Neural network) mapt N dimensionale input naar M dimensionale output en gaat hierbij zelf op zoek naar hoe de mapping exact moet gebeuren. Het is een optimalisatieprobleem waarbij er een optimalisatie gebeurd om de fout zo klein mogelijk te maken.\n",
    "\n",
    "Onderstaande afbeelding is een neuraal netwerk met 3 inputs & 1 output knoop.  \n",
    "De input bestaat uit een lijst van cijfers en ook de output is een een lisjt van cijfers. De ontwerper van het neuraal netwerk zal dus altijd zelf zijn probleem moeten vertalen naar een rij cijfers en ook van de output cijfers terug naar het probleem. \n",
    "![alt text](img/NN1.png)\n",
    "Naast de input & output is er ook een hidden layer in het netwerk te zien. Deze hidden layer kan beschouwd worden als een tussenresultaat.  \n",
    "\n",
    "\n",
    "De waarde van een hidden layer knoop wordt bepaald door een lineaire combinatie te maken van al de waardes uit de vorige layer, voorgesteld door de oranje pijlen in de figuur. Deze lineaire combinatie zijn de gewichten van het netwerk en worden geinitialiseerd met random waardes. Naast de lineaire combinatie is er ook altijd een activatie-functie per knoop. Dit is een niet lineaire functie die van belang is omdat  hidden layers anders wiskundig gezien geen meerwaarde bieden, de lineaire combinaties van verschillende layers na elkaar zonder activatie-functie kunnen anders namelijk vereenvoudigd worden tot 1 lineaire combinatie. Het trainen van een neuraal netwerk is niets anders dan het aanpassen van de gewichten van de lineaire combinatie om een nauwkeuriger antwoord te bekomen.\n",
    "\n",
    "Lineaire combinatie waarbij a<sub>i</sub> het gewicht is en u<sub>i</sub> de waarde uit de vorige layer.\n",
    "![alt text](img/lineaire_combinatie.svg)\n",
    "\n",
    "Een veel gebruikte activatie-functie is ReLu:\n",
    "![alt text](img/Relu.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainen van een neuraal netwerk\n",
    "Het trainen van een neuraal netwerk is niets anders dan het zoeken van goede gewichten voor de eerder besproken lineaire combinaties. Er bestaan verschillende manieren om dit te doen maar de meest voorkomende is gradient descent die hier iets zal worden toegelicht.\n",
    "\n",
    "#### Gradient descent\n",
    "Het trainen van een neuraal netwerk gebeurd door het netwerk veel voorbeelden te geven waar het resultaat van gekent is. De input van een gekend voorbeeld wordt via de input knopen, door verschillende lineaire combinaties uiteindelijk bij de uitput knoop terecht. Initieel zal de output knoop een willekeurig resultaat geven en kan dit gegeven resultaat (ŷ) vergeleken worden met het gewenste resultaat (y). We willen dit verschil minimaliseren.\n",
    "\n",
    "##### Loss-functie:\n",
    "Het vergelijken van het gewenste resultaat met het bekomen resultaat wordt ook wel de loss of error genoemd. Er zijn verschillende manieren om deze vergelijking te doen en deze hebben hun eigen impact op het resultaat. Zo zal een mean square loss __(ŷ - y)<sup>2</sup>__ het belangrijker vinden om outliers correct te labelen in vergelijking met een mean absolute loss __(ŷ - y)__. \n",
    "\n",
    "Neem bijvoorbeeld onderstaande tabellen, we zien dat table 2 een outlier van 15 heeft wat zorgt voor een groot verschil in loss. Een hoge loss betekend dat de dat de gewichten in het netwerk een grotere aanpassing zullen ondergaan om de fout te verkleinen.\n",
    "\n",
    "<table>\n",
    "<tr> <th> Table 1 </th> <th> Table 2 </th> </tr>\n",
    "    \n",
    "<tr><td>\n",
    "    \n",
    "| Error | abs(error)  | error<sup>2</sup>  | \n",
    "| :----:|:-----------:| :-----------------:|\n",
    "| 1     |  1          | 1                  |\n",
    "| -2    |  2          | 2                  |\n",
    "| -0.5  | 0.5         | 0.25               |\n",
    "| 1.5   | 1.5         | 2.25               |\n",
    "    \n",
    "    Mean square loss: 1\n",
    "    Mean absolute loss: 1.22\n",
    "\n",
    "</td><td>\n",
    "\n",
    "| Error | abs(error)  | error<sup>2</sup>  |\n",
    "| :----:| :----------:| :-----------------:|\n",
    "|   1   | 1           | 1                  |\n",
    "|  -2   | 2           | 4                  | \n",
    "|  -0.5 | 0.5         | 0.25               |\n",
    "|  15   | 15          | 225                |\n",
    "\n",
    "    Mean square loss: 3.8\n",
    "    Mean absolute loss: 6.79\n",
    "</td></tr>\n",
    "</table>\n",
    "\n",
    "##### [Backpropagation](https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/)\n",
    "_Dit is wiskundig het ingewikkeldste deel, bekijk de link onder de titel voor een uitgewerkt voorbeeld_  \n",
    "\n",
    "Eens we een loss hebben berekend kunnen we de gewichten gaan aanpassen door middel van backpropagation. We willen weten hoeveel de output veranderd als we een bepaald gewicht veranderen. Vertalen we dit wiskundig komt dit overeen met het nemen van de afgeleiden van de error naar het gewicht. Met de kettingregel kunnen we dit vereenvoudigen naar 3 eenvoudigere afgeleiden. Namelijk de afgeleiden van de loss naar predictie, de afgeleiden van de predictie naar de input (voor de activatiefunctie) en de afgeleiden van de input naar het gewicht. Berekenen we deze 3 eenvoudigere afgeleiden weten we wat de invloed van een verandering van het gewicht zal doen op het resultaat. We weten echter nog niet exact hoe groot deze verandering zal moeten zijn. Daarom vermeningvuldigen we dit ook met een learning rate. Het nemen van een grote learning rate zorgt er voor dat het netwerk snel zal leren maar dat het niet nauwkeurig genoeg gaat leren. Het nemen van een kleine learning rate zorgt ervoor dat het netwerk er heel lang over zal doen om iets nieuws te leren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kracht van een neuraal netwerk:\n",
    "Het idee achter een neuraal netwerk is niet complex of vernieuwend en kan uiterst efficient gebeuren met een GPU. Net omdat het berekenen van lineaire combinaties veel onafhankelijke kleine berekeningen zijn die men in een matrix kan voorstellen om op die manier niet 1 maar X inputs gelijktijdig te bepalen. Bovendien geldt dit voor zowel  forward (predictie) als backwards (training) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Veel gebruikte soorten neuraal netwerk\n",
    "* Neuraal netwerk: Simpel neuraal netwerk zoals bovenstaande figuur\n",
    "* Deep neuraal netwerk: Een neuraal netwerk met meer dan 1 hidden layer. Voorbeeld: http://scs.ryerson.ca/~aharley/vis/fc/\n",
    "* Convolutioneel neuraal netwerk: Een neuraal netwerk waardat een subset van de input gebruikt wordt voor het bepalen van een hidden layer knoop ipv al de inputs samen. Ook worden de zelfde gewichten gebruikt voor verschillende input subsets. Voorbeeld: http://scs.ryerson.ca/~aharley/vis/conv/\n",
    "* RNN (Recurrent neuraal netwerk): Een neuraal netwerk waarbij de output (of tussenresultaat) gebruikt wordt in een volgende iteratie van het netwerk. Handig als er tijdsafhankelijkheid is in het netwerk\n",
    "* LSTM netwerk (long-short-term-memory): Een RNN dat tijdsafhankelijkheid langer kan onthouden dan een RNN\n",
    "* Auto-encoder: een deep neuraal netwerk waarbij de input en output het zelfde zijn maar waarbij een hidden layer minder knopen bevat. Na training worden de knopen vanaf deze hidden layer tot de output weggegooit om zo een dimensie reductie te bekomen. N dimensie input naar M dimensie hidden layer.\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beperkingen\n",
    "* Veel trainings-data nodig\n",
    "* Veel trainings-tijd nodig\n",
    "* Vaak krachtige hardware nodig voor training, predictie is dit een minder belangrijke vereisten\n",
    "* altijd zelfde input grootte vereist\n",
    "* vertaling van probleem naar array en terug naar probleem kan lastig zijn\n",
    "* Moeilijk te beredeneren waarom een bepaalde output wordt gegeven\n",
    "* Input moet beperkt blijven (niet naar oneindig gaan) omdat anders oneindige loss hebt\n",
    "* Netwerk moet afleidbaar zijn\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In deze demo gaan we een neuraal netwerk trainen om handgeschreven cijfers van de mnist dataset te herkennen. We maken hier 2 verschillende netwerken voor. 1 fully connected netwerk (Deep neuraal netwerk) en 1 convolutioneel neuraal netwerk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dependecies:\n",
    "* Numpy:\n",
    "* Keras van Tensorflow\n",
    "* mnist dataset: De MNIST dataset bestaat uit 28x28 greyscaled afbeeldingen van handgeschreven cijfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import Sequential, losses, optimizers, utils\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import load_model, save_model\n",
    "from matplotlib import pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We starten met te bekijken van de dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.  26. 207. 253.  63.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0. 104. 252. 252. 140.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.  19. 209. 252. 252. 110.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0. 178. 252. 252. 157.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0. 225. 252. 252. 112.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0. 226. 253. 240.  63.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  101. 249. 252. 223.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  32.\n",
      "  222. 252. 252. 192.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 140.\n",
      "  253. 252. 214.  28.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 140.\n",
      "  253. 252. 195.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  29. 253.\n",
      "  255. 253. 133.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 154. 252.\n",
      "  253. 223.  37.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  45. 234. 252.\n",
      "  253.  58.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  10. 156. 252. 252.\n",
      "  240.  24.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 163. 252. 252. 252.\n",
      "  140.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 226. 253. 253. 253.\n",
      "  141.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0. 147. 249. 252. 252. 204.\n",
      "   94.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0. 111. 253. 252. 252. 245.  87.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0. 126. 253. 252. 245. 121.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0. 174. 252. 195.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "def show_img(img_item):\n",
    "    image = np.array(img_item, dtype='float')\n",
    "    pixels = image.reshape((28, 28))\n",
    "    plt.imshow(pixels, cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "def show_raw(img_item):\n",
    "    image = np.array(img_item, dtype='float')\n",
    "    pixels = image.reshape((28, 28))\n",
    "    print(pixels)\n",
    "    \n",
    "def get_item(x_set, y_set, index = None):\n",
    "    index = random.randint(0, len(x_set) - 1) if index is None else index\n",
    "    return x_set[index], y_set[index]\n",
    "     \n",
    "x_item, y_item = get_item(x_train, y_train, 14945)\n",
    "show_img(x_item)\n",
    "show_raw(x_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zien dat de afbeelding bestaat uit een 28x28 rijen met pixel waardes tussen de 0 en 255. Een neuraal netwerk is erg gevoeling aan de input en het is daarom verstandig deze pixels eerst te normaliseren naar waardes tussen 0 en 1. We kunnen dit eenvoudig doen door iedere pixel te delen door zijn maximale waarde, namelijk 255.\n",
    "\n",
    "Ook zal de shape van de input wordt aangepast, we passen dit aan zodat het kan dienen als input naar het CNN netwerk omdat er in Keras een Flatten layer bestaat die een 2D input flattend naar een 1D input. Deze 1D input kunnen we dan vervolgens gebruiken in ons DNN netwerk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_X_data(x_unprepared_data):\n",
    "    img_rows = x_unprepared_data.shape[1]\n",
    "    img_cols = x_unprepared_data.shape[2]\n",
    "    x_data = x_unprepared_data.reshape(x_unprepared_data.shape[0], img_rows, img_cols, 1)\n",
    "    \n",
    "    x_data = x_data.astype('float32')\n",
    "    x_data /= 255\n",
    "    return x_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naast de input bekijken we ook eventjes naar de output.\n",
    "We zien dat dit 1 cijfer is, een neuraal netwerk is in staat om een regressie-probleem op te lossen maar heeft het daar vaak lastig mee. Omdat we in dit geval maar 10 exacte cijfers kunnen bekomen kunnen we dit probleem beter vertalen naar een classificatie ipv een regressie. We doen dit door one-hot-encoding toe te passen.\n",
    "\n",
    "one-hot-encoding: Een lijst waarbij ieder element uit de lijst een 0 of een 1 kan zijn. Een 0 element betekend dat de betekenis aan dit element niet waar is, een 1 betekend dat dit wel waar is. Keras heeft hier een eenvoudige util functie voor namelijk utils.to_cateogrical/2.  \n",
    "bv. Het cijfer 5 in de one-hot-encoding in ons probleem wordt weergegeven als [0,0,0,0,0,1,0,0,0,0] (zero-indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_Y_data(y_unpreprared_data):\n",
    "    y_data = utils.to_categorical(y_unpreprared_data, 10)\n",
    "    return y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu dat we weten hoe we onze input en output gaan voorstellen gaan we werkelijk het neuraal netwerk maken. Zoals reeds gezegd zouden er 2 modelen gemaakt worden. Namelijk een DNN en een CNN model.  \n",
    "\n",
    "_De input van het DNN zal ook 2 dimensionaal zijn maar zal beginnen met een Flatten layer die een 2D structuur terug 1D maakt. Dit doen we zodat we dezelfde preprocessing functie kunnen gebruiken voor ons DNN en CNN model_\n",
    "\n",
    "We zullen 2 manieren zien om ons model te definieren.\n",
    "\n",
    "Model 1: Deep neuraal netwerk\n",
    "- Input layer: Flatten\n",
    "    - Input shape: 1x28x28\n",
    "- hidden layer 1: Dense\n",
    "    - nodes: 512\n",
    "    - Activatie functie: Relu\n",
    "- hidden layer 2: Dense\n",
    "    - nodes: 256\n",
    "    - Activatie functie: Relu\n",
    "- hidden layer 3: Dense\n",
    "    - nodes: 128\n",
    "    - Activatie functie: Relu\n",
    "- hidden layer 4: Dense\n",
    "    - nodes: 32\n",
    "    - Activatie functie: Relu\n",
    "- output layer: Dense\n",
    "    - nodes: 10 (de 10 cijfers die te herkennen zijn, 1 output per cijfer)\n",
    "    - Activatie functie: Softmax (Handig voor bepaling van waarschijnlijkheid per output)\n",
    "    - optimizer: Stochastic Gradient descent (gradient descent met momentum)\n",
    "    - loss: categorical crossentropy (Handig als er one-hot encoding is gebeurd voor de output)\n",
    "\n",
    "        \n",
    "Model 2: Convolutioneel neuraal netwerk\n",
    "- Input layer: Conv2D\n",
    "    - Input shape: 1x28x28\n",
    "    - nodes: 32\n",
    "    - kernel_size: 3x3 (Grootte van het convolutie raster) \n",
    "    - Activatie functie: Relu\n",
    "- hidden layer 1: Conv2D\n",
    "    - nodes: 64\n",
    "    - kernel_size: 3x3 (Grootte van het convolutie raster) \n",
    "    - Activatie functie: Relu\n",
    "- hidden layer 2: Flatten\n",
    "- hidden layer 3: Dense\n",
    "    - nodes: 128\n",
    "    - Activatie functie: Relu\n",
    "- hidden layer 4: Dense\n",
    "    - nodes: 128\n",
    "    - Activatie functie: Relu\n",
    "- output layer: Dense\n",
    "    - nodes: 10 (de 10 cijfers die te herkennen zijn, 1 output per cijfer)\n",
    "    - Activatie functie: Softmax (Handig voor bepaling van waarschijnlijkheid per output)\n",
    "    - optimizer: Stochastic Gradient descent (gradient descent met momentum)\n",
    "    - loss: categorical crossentropy (Handig als er one-hot encoding is gebeurd voor de output)\n",
    "    \n",
    "    \n",
    "Een convolutielaag bekijkt beschouwd niet al de input maar bekijkt een klein deel van de input. Op deze manier kan er op zoek gegaan worden naar lokale afhankelijkheden. Dit is handig bijvoorbeeld interessant bij een afbeelding aangezien de uiterst linker boven pixel en de meest rechter onder pixel weinig verband houden met elkaar. Het neuraal netwerk hier in begeleiden mbv een convolutie laag zorgt ervoor dat het netwerk sneller zal trainen. Uit onderzoek is gebleken dat een eerste convolutie laag vaak op zoek gaat naar eenvoudige patronen. (Rechte lijnen in bepaalde richtingen), een 2de laag zal deze eenvoudige patronen vaak combineren tot een iets complex patroon. (een vierkant, een cirkel,..) Verdere convolutie lagen zullen dus steeds complexere patronen kunnen herkennen.\n",
    "\n",
    "In onderstaande afbeelding zie je hoe een convolutie te werk gaat. De grootte van de kernel is bepaald adhv de parameter, de cijfers in de kernel zijn de gewichten die door het netwerk bepaald/gezocht moeten worden. De kernel laat zien naar wat voor soort patronen er op zoek gegaan zal worden.\n",
    "![text alt](img/keras_conv2d.gif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of DNN model\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 570,602\n",
      "Trainable params: 570,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Summary of CNN model\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               4718720   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 4,755,338\n",
      "Trainable params: 4,755,338\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (28,28,1)\n",
    "def create_model_DNN():\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=input_shape))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(loss=losses.categorical_crossentropy,\n",
    "                  optimizer=\"sgd\",\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_model_CNN():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(loss=losses.categorical_crossentropy,\n",
    "                  optimizer=\"sgd\",\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model_dnn = create_model_DNN()\n",
    "model_cnn = create_model_CNN()\n",
    "print(\"Summary of DNN model\")\n",
    "model_dnn.summary()\n",
    "print(\"\")\n",
    "print(\"Summary of CNN model\")\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu dat we onze netwerken hebben gaan we deze netwerken trainen. Initeel zijn de gewichten namelijk willekeurig maar deze moeten getraind worden om een correcte voorspelleing te doen van de output. Dit kan aan de hand van de fit functie waarbij zowel X als Y waardes worden meegegeven. De batch_size parameter bepaald hoeveel voorbeelden er gelijktijdig bekeken worden. Wiskundig gezien bepaald dit de grootte van de matrix die gebruikt wordt voor de berekening. Met de epochs parameter verteld je dat het netwerk al de trainingsdata 12x moet herbekijken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, name):\n",
    "    print(\"start training \" + str(name))\n",
    "    x_prep_train = prepare_X_data(x_unprepared_data=x_train)\n",
    "    y_prep_train = prepare_Y_data(y_unpreprared_data=y_train)\n",
    "    model.fit(x_prep_train, y_prep_train, batch_size=128, epochs=12, verbose=1)\n",
    "    print(\"Saving model \" + str(name))\n",
    "    save_model(model=model, filepath=str(name) + \".h5\")\n",
    "    print(\"Finished training model \" + str(name))\n",
    "    \n",
    "# train_model(model_dnn, \"dnn\")\n",
    "model_dnn = load_model(\"dnn.h5\")\n",
    "print(\"\")\n",
    "# train_model(model_cnn, \"cnn\")\n",
    "model_cnn = load_model(\"cnn.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na het trainen van het netwerk is het belangrijk om te kijken of het netwerk ook goed werkt voor ongeziene voorbeelden. Het kan namelijk gebeuren dat het netwerk te vaak naar de trainingsdata kijkt met als gevolgd dat het niet goed veralgemeend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model dnn\n",
      "loss: 0.13984222630783916\n",
      "accuracy: 0.9579\n",
      "\n",
      "Model cnn\n",
      "loss: 0.07701360287913121\n",
      "accuracy: 0.9764\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_model(model, name):\n",
    "    x_prep_test = prepare_X_data(x_unprepared_data=x_test)\n",
    "    y_prep_test = prepare_Y_data(y_unpreprared_data=y_test)\n",
    "    result =  model.evaluate(x_prep_test, y_prep_test, verbose=0)\n",
    "    print(\"Model \" + str(name))\n",
    "    print(\"loss: \" + str(result[0]))\n",
    "    print(\"accuracy: \" + str(result[1]))\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "test_model(model_dnn, \"dnn\")\n",
    "test_model(model_cnn, \"cnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tot slot bekijken we even concreet de output van het netwerk en hoe de output vertaald moet worden naar het probleem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dit item zal eerst moeten worden preprocessed volgens de zelfde voorwaarden als de trainingdata zodat we dit aan het neuraal netwerk kunnen geven.\n",
    "\n",
    "Vervolgens laten we het model een voorspelling doen en krijgen we een lijst van 10 elementen terug. De waarde van ieder element in de lijst zegt hoe waarschijnlijk dat dit cijfer het correcte antwoord is. We moeten dus op zoek gaan naar de plaats van het grootste element, dit is de voorspelling van het netwerk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model DNN\n",
      "Prediction array: [2.7427259e-07 9.9618214e-01 2.4169944e-03 4.5651227e-04 7.0355991e-06\n",
      " 1.6187087e-05 1.3758052e-04 1.5896323e-04 6.0732698e-04 1.7038357e-05]\n",
      "Prediction: 1\n",
      "Ground truth: 1\n",
      "\n",
      "Model CNN\n",
      "Prediction array: [1.5688279e-07 9.9964213e-01 1.1929138e-04 6.4715607e-07 6.3196040e-07\n",
      " 5.8135359e-09 5.1249748e-07 9.0141912e-05 1.4625979e-04 2.2095237e-07]\n",
      "Prediction: 1\n",
      "Ground truth: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def predict(model, x_item, y_test = None):\n",
    "    X = prepare_X_data(x_unprepared_data=np.array([x_item]))\n",
    "    prediction = model.predict(X)\n",
    "    print(\"Prediction array: \" + str(prediction[0]))\n",
    "    print(\"Prediction: \" + str(np.argmax(prediction)))\n",
    "    if y_test is not None:\n",
    "        print(\"Ground truth: \" + str(y_test))\n",
    "        print(\"\")\n",
    "    \n",
    "show_img(x_item)\n",
    "print(\"Model DNN\")\n",
    "predict(model_dnn, x_item, y_item)\n",
    "print(\"Model CNN\")\n",
    "predict(model_cnn, x_item, y_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Er is ook een methode voorzien om meerdere, eventueel random geselecteerde, items te voorspellen. Zoals te zien in de code kunnen er meerdere inputs gelijktijdig aan het netwerk worden gegeven zodat de berekening opnieuw gedaan kan worden als een matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction array: [1.7604547e-05 4.0810901e-06 1.6783097e-05 1.1855512e-04 2.7889939e-02\n",
      " 3.2263694e-04 2.5438665e-06 9.0707161e-02 6.2763441e-04 8.8029295e-01]\n",
      "Prediction: 9\n",
      "Ground truth: 9\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAMrElEQVR4nO3db4hd9Z3H8c9ntXlgWkiyYnawsbbFBxVxrQSpJGpK02J8EvugkjxYlI07FRuosLCG9EEFU5D+k4JamFLpdOlaCtFWQ2gbQlh3H1gch6hxsq2uZNs0Q2Y1gRrmQap++2BOyjTec+7knnPuuZnv+wXDvfd87z3nyyWf/M655577c0QIwPL3d103AGA4CDuQBGEHkiDsQBKEHUji0mFuzDYf/QMtiwj3Wl5rZLd9u+3f2n7D9q466wLQLg96nt32JZJ+J+nzko5LelHS9oiYqXgNIzvQsjZG9pskvRERb0bEWUk/lbS1xvoAtKhO2K+U9IdFj48Xy/6G7XHbU7anamwLQE11PqDrtavwgd30iJiQNCGxGw90qc7IflzSukWPPyrpRL12ALSlTthflHSN7Y/bXiFpm6Rnm2kLQNMG3o2PiHdt75T0K0mXSHoyIl5rrDMAjRr41NtAG+OYHWhdK1+qAXDxIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJgadsBtp23333VdYff/zxyvr8/Hxp7bbbbqt87fT0dGX9YlQr7LaPSXpH0nuS3o2I9U00BaB5TYzsn42ItxpYD4AWccwOJFE37CHp17Zfsj3e6wm2x21P2Z6quS0ANdTdjd8QESdsXyHpgO3/iYjnFz8hIiYkTUiS7ai5PQADqjWyR8SJ4nZO0jOSbmqiKQDNGzjstlfa/si5+5K+IOlIU40BaFad3fi1kp6xfW49/xERv2ykK6Rw3XXXVdb37NlTWY+oPiq87LLLSmvXXntt5Ws5z75IRLwp6R8b7AVAizj1BiRB2IEkCDuQBGEHkiDsQBJc4orO3HzzzZX1VatW1Vr/gQMHSmuzs7O11n0xYmQHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQ4z45WrV69urS2c+fOWuuenJysrO/YsaPW+pcbRnYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSML9fo630Y0xI8yys3Llysr6/v37S2sbNmyofO3MzExlffPmzZX1ubm5yvpyFRHutZyRHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeS4Hp21HLXXXdV1jdu3Djwuh999NHKetbz6IPqO7LbftL2nO0ji5atsX3A9uvFbfkvFAAYCUvZjf+RpNvPW7ZL0sGIuEbSweIxgBHWN+wR8bykU+ct3irp3G8CTUq6s9m2ADRt0GP2tRExK0kRMWv7irIn2h6XND7gdgA0pPUP6CJiQtKExIUwQJcGPfV20vaYJBW3fCwKjLhBw/6spLuL+3dL+kUz7QBoS9/r2W0/JWmTpMslnZT0dUk/l/QzSVdJ+r2kL0XE+R/i9VoXu/EXmS1btlTW9+3bV1mv+vd16NChytf2O4d/+vTpynpWZdez9z1mj4jtJaXP1eoIwFDxdVkgCcIOJEHYgSQIO5AEYQeS4BJXVOp36q2fM2fOlNYefPDBytdyaq1ZjOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATn2ZPrd657fLzeL4o999xzpbXp6ela68aFYWQHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQ4z57ctm3bKuuXXlr9T2R+fr6y3m/aZQwPIzuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJMF59mXu4Ycfrqxff/31tdY/NzdXWeea9dHRd2S3/aTtOdtHFi17yPYfbR8u/u5ot00AdS1lN/5Hkm7vsfzRiLih+NvfbFsAmtY37BHxvKRTQ+gFQIvqfEC30/YrxW7+6rIn2R63PWV7qsa2ANQ0aNi/L+mTkm6QNCvpO2VPjIiJiFgfEesH3BaABgwU9og4GRHvRcT7kn4g6aZm2wLQtIHCbnts0cMvSjpS9lwAo6HveXbbT0naJOly28clfV3SJts3SApJxyR9ub0W0c9VV11VWrvnnnsqXxsRlfX9+6tPtOzatauyjtHRN+wRsb3H4h+20AuAFvF1WSAJwg4kQdiBJAg7kARhB5LgEtdl4N577y2tjY2NldaWYs+ePZX1mZmZWuvH8DCyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASnGe/CNx6662V9fvvv3/gde/bt6+yzk9BLx+M7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQhPv9lHCjG7OHt7Fl5NChQ5X1W265ZeB1b9y4sbL+wgsvDLxudCMi3Gs5IzuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJMH17CNgy5YtlfVNmzZV1s+ePVta2717d+VrOY+eR9+R3fY624dsH7X9mu2vFsvX2D5g+/XidnX77QIY1FJ249+V9K8R8SlJn5H0FdvXStol6WBEXCPpYPEYwIjqG/aImI2I6eL+O5KOSrpS0lZJk8XTJiXd2VKPABpwQcfstq+W9GlJv5G0NiJmpYX/EGxfUfKacUnjNfsEUNOSw277w5L2SnogIv5k9/yu/QdExISkiWIdXAgDdGRJp95sf0gLQf9JRDxdLD5pe6yoj0maa6dFAE3oe4mrF4bwSUmnIuKBRcu/JentiHjE9i5JayLi3/qsi5G9hxMnTlTW165dW1l/+eWXS2s33njjQD3h4lV2ietSduM3SPonSa/aPlws2y3pEUk/s71D0u8lfamBPgG0pG/YI+K/JZUdoH+u2XYAtIWvywJJEHYgCcIOJEHYgSQIO5AEl7gOwebNmyvrq1atqrX+vXv31no9cmBkB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkOM8+BGNjY5X1FStWVNbffvvtyvoTTzxxwT0hH0Z2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiC8+xDMDMzU1mfn5+vrD/22GOV9dOnT19wT8iHkR1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkljK/OzrJP1Y0j9Iel/SRER8z/ZDkv5F0v8XT90dEfv7rIv52YGWlc3PvpSwj0kai4hp2x+R9JKkOyXdJelMRHx7qU0QdqB9ZWFfyvzss5Jmi/vv2D4q6cpm2wPQtgs6Zrd9taRPS/pNsWin7VdsP2l7dclrxm1P2Z6q1yqAOvruxv/1ifaHJf2npG9ExNO210p6S1JIelgLu/r/3Gcd7MYDLRv4mF2SbH9I0j5Jv4qI7/aoXy1pX0Rc12c9hB1oWVnY++7G27akH0o6ujjoxQd353xR0pG6TQJoz1I+jd8o6b8kvaqFU2+StFvSdkk3aGE3/pikLxcf5lWti5EdaFmt3fimEHagfQPvxgNYHgg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJDHvK5rck/d+ix5cXy0bRqPY2qn1J9DaoJnv7WFlhqNezf2Dj9lRErO+sgQqj2tuo9iXR26CG1Ru78UAShB1IouuwT3S8/Sqj2tuo9iXR26CG0lunx+wAhqfrkR3AkBB2IIlOwm77dtu/tf2G7V1d9FDG9jHbr9o+3PX8dMUcenO2jyxatsb2AduvF7c959jrqLeHbP+xeO8O276jo97W2T5k+6jt12x/tVje6XtX0ddQ3rehH7PbvkTS7yR9XtJxSS9K2h4RM0NtpITtY5LWR0TnX8CwfaukM5J+fG5qLdvflHQqIh4p/qNcHREPjkhvD+kCp/FuqbeyacbvUYfvXZPTnw+ii5H9JklvRMSbEXFW0k8lbe2gj5EXEc9LOnXe4q2SJov7k1r4xzJ0Jb2NhIiYjYjp4v47ks5NM97pe1fR11B0EfYrJf1h0ePjGq353kPSr22/ZHu862Z6WHtumq3i9oqO+zlf32m8h+m8acZH5r0bZPrzuroIe6+paUbp/N+GiLhR0hZJXyl2V7E035f0SS3MATgr6TtdNlNMM75X0gMR8acue1msR19Ded+6CPtxSesWPf6opBMd9NFTRJwobuckPaOFw45RcvLcDLrF7VzH/fxVRJyMiPci4n1JP1CH710xzfheST+JiKeLxZ2/d736Gtb71kXYX5R0je2P214haZukZzvo4wNsryw+OJHtlZK+oNGbivpZSXcX9++W9IsOe/kbozKNd9k04+r4vet8+vOIGPqfpDu08In8/0r6Whc9lPT1CUkvF3+vdd2bpKe0sFv3Zy3sEe2Q9PeSDkp6vbhdM0K9/bsWpvZ+RQvBGuuot41aODR8RdLh4u+Ort+7ir6G8r7xdVkgCb5BByRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ/AUU+/NzgaXGyAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction array: [5.10145277e-08 9.98164475e-01 1.71866865e-04 7.58919632e-04\n",
      " 1.19777207e-04 1.06858155e-04 3.71179849e-05 4.80888411e-04\n",
      " 1.21478624e-04 3.87126856e-05]\n",
      "Prediction: 1\n",
      "Ground truth: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def random_predict(model, nb_of_items, x, y = None):\n",
    "    indexes = np.random.choice(range(len(x)), nb_of_items)\n",
    "    X_items = x[indexes]\n",
    "    Y_items = y[indexes]\n",
    "    \n",
    "    X = prepare_X_data(x_unprepared_data=np.array(X_items))\n",
    "    prediction = model.predict(X)\n",
    "    for i in range(nb_of_items):\n",
    "        show_img(X_items[i])\n",
    "        print(\"Prediction array: \" + str(prediction[i]))\n",
    "        print(\"Prediction: \" + str(np.argmax(prediction[i])))\n",
    "        if y is not None:\n",
    "            print(\"Ground truth: \" + str(Y_items[i]))\n",
    "            print(\"\")\n",
    "            \n",
    "random_predict(model_dnn, 2, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tot slot zullen we nog eens een netwerk opslaan en terug opladen. We printen te summary nog een keer zodat duidelijk te zien is dat het CNN netwerk is opgeslagen. Ook kunnen we de predictie voor het opslaan en na het opslaan met elkaar vergelijken en zien we dat de resultaten exact het zelfde zijn. We zijn dus zeker dat dit over het zelfde netwerk gaat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction array: [1.5688279e-07 9.9964213e-01 1.1929138e-04 6.4715607e-07 6.3196040e-07\n",
      " 5.8135359e-09 5.1249748e-07 9.0141912e-05 1.4625979e-04 2.2095237e-07]\n",
      "Prediction: 1\n",
      "Ground truth: 1\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               4718720   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 4,755,338\n",
      "Trainable params: 4,755,338\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Prediction array: [1.5688279e-07 9.9964213e-01 1.1929138e-04 6.4715607e-07 6.3196040e-07\n",
      " 5.8135359e-09 5.1249748e-07 9.0141912e-05 1.4625979e-04 2.2095237e-07]\n",
      "Prediction: 1\n",
      "Ground truth: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict(model_cnn, x_item, y_item)\n",
    "\n",
    "save_model(model=model_cnn, filepath=\"example.h5\")\n",
    "model = load_model(\"example.h5\")\n",
    "model.summary()\n",
    "\n",
    "predict(model, x_item, y_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural_network_env",
   "language": "python",
   "name": "neural_network_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
