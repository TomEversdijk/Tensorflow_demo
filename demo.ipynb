{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network, Keras & Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curriculum vitae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Achtergrond\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tom Eversdijk  \n",
    "Opleiding: Burgerlijk ingenieur computerwetenschappen - Artificiele intelligentie @KULeuven, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projecten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thesis: Intelligence trafficlights\n",
    "Ontwerpen van een systeem voor intelligente verkeerslichten dat de verkeersdoorstroming optimaliseert. Het doel was om te zorgen voor globale optimalisatie door rekening te houden met naburige kruispunten.\n",
    "\n",
    "NN: \n",
    "* input: wachttijd & aantal wachtende voertuigen per rijstrook voor een kruispunt [numeric] .\n",
    "* Output: Combinatie van verkeerslichten die gelijktijdig op groen gezet worden [0:1].\n",
    "* type: Deep neural network & Q-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Machine learning project: Dots & Boxes machine learning\n",
    "Ontwerpen van een AI die het spel [Dots & Boxes](https://nl.wikipedia.org/wiki/Kamertje_verhuren_(spel)) kan spelen.  \n",
    "\n",
    "NN:\n",
    "* input: Representatie van het speelbord [boolean]\n",
    "* output: Score voor bepaalde zet\n",
    "* Type: Deep Convolutional neural network getrained door self-play"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KULeuven DTAI: Connect 4 demo\n",
    "Bedenken, ontwerpen en ontwikkelen van een interactieve AI-demo ter promotie van departement computerwetenschappen specialisatie AI. Dit is gebeurd door een AI die het spel 4-op-een-rij kan spelen waarbij gebruikers de redenering van de AI kunnen bekijken en verschillende parameters kunnen instellen. Hier is gebruik gemaakt van Monte Carlo Tree Search (MCTS) & Deep Convolutional Neural\n",
    "\n",
    "Bevat een value & policy network, gelijkaardig aan [Alpha-Go](https://deepmind.com/research/case-studies/alphago-the-story-so-far)  \n",
    "\n",
    "Policy NN:\n",
    "* input: Representatie van het speelbord [-1;0;1]\n",
    "* output: Scores per mogelijk zet \n",
    "* Type: Deep Convolutional neural network getrained door self-play\n",
    "\n",
    "Value NN\n",
    "* input: Representatie van het speelbord [-1;0;1]\n",
    "* output: Waarschijnlijkheid van wins in de huidige situatie\n",
    "* Type: Deep Convolutional neural network getrained door MCTS plays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wat is een neuraal network?\n",
    "NN (Neural network) mapt N dimensionale input naar M dimensionale output en gaat hierbij zelf op zoek naar hoe de mapping exact moet gebeuren. Het is een optimalisatieprobleem waarbij er een optimalisatie gebeurd om de fout zo klein mogelijk te maken.\n",
    "\n",
    "Onderstaande afbeelding is een neuraal netwerk met 3 inputs & 1 output knoop.  \n",
    "De input bestaan uit cijfers en ook de output zijn cijfer. De ontwerper van het neuraal netwerk zal dus altijd zelf zijn probleem moeten vertalen naar een rij cijfers en ook van de output cijfers terug naar het probleem. \n",
    "![alt text](img/NN1.png)\n",
    "Naast de input & output is er ook een hidden layer in het netwerk te zien. Deze hidden layer kan beschouwd worden als een tussenresultaat.  \n",
    "\n",
    "\n",
    "De waarde van een hidden layer knoop wordt bepaald door een lineaire combinatie te maken van al de waardes uit de vorige layer, voorgesteld door de oranje pijlen in de figuur. Deze lineaire combinatie zijn de gewichten van het netwerk en worden geinitialiseerd met random waardes. Naast de lineaire combinatie is er ook altijd een activatie-functie per knoop. Dit is een niet lineaire functie die van belang is omdat  hidden layers anders wiskundig gezien geen meerwaarde bieden, de lineaire combinaties van verschillende layers na elkaar zonder activatie-functie kunnen anders namelijk vereenvoudigd worden tot 1 lineaire combinatie. Het trainen van een neuraal netwerk is niets anders dan het aanpassen van de gewichten van de lineaire combinatie om een nauwkeuriger antwoord te bekomen.\n",
    "\n",
    "Lineaire combinatie waarbij a<sub>i</sub> het gewicht is en u<sub>i</sub> de waarde uit de vorige layer.\n",
    "![alt text](img/lineaire_combinatie.svg)\n",
    "\n",
    "Een veel gebruikte activatie-functie is ReLu:\n",
    "![alt text](img/Relu.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainen van een neuraal netwerk\n",
    "Het trainen van een neuraal netwerk is niets anders dan het zoeken van goede gewichten voor de eerder besproken lineaire combinaties. Er bestaan verschillende manieren om dit te doen maar de meest voorkomende is gradient descent die hier iets zal worden toegelicht.\n",
    "\n",
    "#### Gradient descent\n",
    "Het trainen van een neuraal netwerk gebeurd door het netwerk veel voorbeelden te geven waar het resultaat van gekent is. De input van een gekend voorbeeld wordt via de input knopen, door verschillende lineaire combinaties uiteindelijk bij de uitput knoop terecht. Initieel zal de output knoop een willekeurig resultaat geven en kan dit gegeven resultaat vergeleken worden met het gewenste resultaat. (De manier van vergelijken kan verschillen afhankelijk van de loss-functie, veel gebruikt is root-mean-square) De berekende error of loss willen we minimaliseren. Door middel van het berekenen van afgeleiden van de lineaire combinaties & activatie functie kan men van achter naar voor de gewichten aanpassen om de fout te minimaliseren. Het minimaliseren gebeurd echter niet in 1x maar in kleine stapjes die bepaald worden door de learning-rate van het netwerk (een gedefinieerde parameter). Dit omdat het verkleine van een fout voor voorbeeld A kan lijden tot een vergroting van de fout voor voorbeeld B. Globaal wordt er veronderstelt dat de veranderingen van gewichten steeds klein genoeg zijn om de gemiddelde fout te minimaliseren, en dit blijkt in de realiteit ook vaak te kloppen. Daarom is het belangrijk ieder voorbeeld meerdere keren te bekijken en ook de volgorde waarin de voorbeelden bekenen worden steeds te veranderen. Bovendien kan een neuraal netwerk ook iets dat het heeft geleerd terug vergeten als dit voorbeeld niet meer terug komt tijdens trainen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kracht van een neuraal netwerk:\n",
    "Het idee achter een neuraal netwerk is niet complex of vernieuwend en kan uiterst efficient gebeuren met een GPU. Net omdat het berekenen van lineaire combinaties veel onafhankelijke kleine berekeningen zijn die men in een matrix kan voorstellen om op die manier niet 1 maar X inputs gelijktijdig te bepalen. Bovendien geldt dit voor zowel  forward (predictie) als backwards (training) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Veel gebruikte soorten neuraal netwerk\n",
    "* Neuraal netwerk: Simpel neuraal netwerk zoals bovenstaande figuur\n",
    "* Deep neuraal netwerk: Een neuraal netwerk met meer dan 1 hidden layer. Voorbeeld: http://scs.ryerson.ca/~aharley/vis/fc/\n",
    "* Convolutioneel neuraal netwerk: Een neuraal netwerk waardat een subset van de input gebruikt wordt voor het bepalen van een hidden layer knoop ipv al de inputs samen. Ook worden de zelfde gewichten gebruikt voor verschillende input subsets. Voorbeeld: http://scs.ryerson.ca/~aharley/vis/conv/\n",
    "* RNN (Recurrent neuraal netwerk): Een neuraal netwerk waarbij de output (of tussenresultaat) gebruikt wordt in een volgende iteratie van het netwerk. Handig als er tijdsafhankelijkheid is in het netwerk\n",
    "* LSTM netwerk (long-short-term-memory): Een RNN dat tijdsafhankelijkheid langer kan onthouden dan een RNN\n",
    "* Auto-encoder: een deep neuraal netwerk waarbij de input en output het zelfde zijn maar waarbij een hidden layer minder knopen bevat. Na training worden de knopen vanaf deze hidden layer tot de output weggegooit om zo een dimensie reductie te bekomen. N dimensie input naar M dimensie hidden layer.\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beperkingen\n",
    "* Veel trainings-data nodig\n",
    "* Veel trainings-tijd nodig\n",
    "* Vaak krachtige hardware nodig voor training, predictie is dit een minder belangrijke vereisten\n",
    "* altijd zelfde input grootte vereist\n",
    "* vertaling van probleem naar array en terug naar probleem kan lastig zijn\n",
    "* Moeilijk te beredeneren waarom een bepaalde output wordt gegeven"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In deze demo gaan we een neuraal netwerk trainen om handgeschreven cijfers van de mnist dataset te herkennen. We maken hier 2 verschillende netwerken voor. 1 fully connected netwerk (Deep neuraal netwerk) en 1 convolutioneel neuraal netwerk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dependecies:\n",
    "* Numpy:\n",
    "* Keras van Tensorflow\n",
    "* mnist dataset: De MNIST dataset bestaat uit 28x28 greyscaled afbeeldingen van handgeschreven cijfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import Sequential, losses, optimizers, utils\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import load_model, save_model\n",
    "from matplotlib import pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We starten met te bekijken van de dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0. 123. 254.  71.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  41.\n",
      "   82. 163. 243. 253. 151.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  82. 214. 253. 254.\n",
      "  253. 254. 253. 254. 253.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.  82. 243. 253. 252. 253.\n",
      "  252. 233. 151. 253. 252.  82.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0. 123. 243. 254. 253. 203.\n",
      "  122.   0.   0. 152. 253. 203.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  40.  50.  50.   0.\n",
      "    0.   0.   0. 152. 252. 203.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0. 152. 253. 203.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0. 152. 252. 203.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.  62. 254. 253. 142.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0. 102. 253. 252.  61.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.  51. 233. 254. 253.  21.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0. 152. 252. 253. 212.  20.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  11.  51. 152.\n",
      "  152. 214. 253. 224.  20.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 123. 213. 252. 253.\n",
      "  252. 253. 252. 203.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.  41. 214. 253. 254. 253. 254.\n",
      "  253. 254. 253. 214.  31.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0. 123. 243. 253. 212. 151. 192. 253.\n",
      "  252. 253. 252. 253. 232.  41.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.  62. 254. 253. 234. 112. 214. 253. 254.\n",
      "  172.   0. 142. 254. 253. 255.  50.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.  41. 223. 253. 252. 253. 252. 253. 252. 131.\n",
      "   10.   0.  20. 213. 252. 253.  50.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.  52. 253. 254. 253. 254. 233. 183.  61.   0.\n",
      "    0.   0.   0.  21. 102.  82.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.  51. 252. 253. 252. 131.  30.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "def show_img(img_item):\n",
    "    image = np.array(img_item, dtype='float')\n",
    "    pixels = image.reshape((28, 28))\n",
    "    plt.imshow(pixels, cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "def show_raw(img_item):\n",
    "    image = np.array(img_item, dtype='float')\n",
    "    pixels = image.reshape((28, 28))\n",
    "    print(pixels)\n",
    "    \n",
    "def get_item(x_set, y_set, index = None):\n",
    "    index = random.randint(0, len(x_set) - 1) if index is None else index\n",
    "    return x_set[index], y_set[index]\n",
    "     \n",
    "x_item, y_item = get_item(x_train, y_train)\n",
    "show_img(x_item)\n",
    "show_raw(x_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zien dat de afbeelding bestaat uit een 28x28 rijen met pixel waardes tussen de 0 en 255. Een neuraal netwerk is erg gevoeling aan de input en het is daarom verstandig deze pixels eerst te normaliseren naar waardes tussen 0 en 1. We kunnen dit eenvoudig doen door iedere pixel te delen door zijn maximale waarde, namelijk 255.\n",
    "\n",
    "Ook zal de shape van de input wordt aangepast, we passen dit aan zodat het kan dienen als input naar het CNN netwerk omdat er in Keras een Flatten layer bestaat die een 2D input flattend naar een 1D input. Deze 1D input kunnen we dan vervolgens gebruiken in ons DNN netwerk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_X_data(x_unprepared_data):\n",
    "    img_rows = x_unprepared_data.shape[1]\n",
    "    img_cols = x_unprepared_data.shape[2]\n",
    "    x_data = x_unprepared_data.reshape(x_unprepared_data.shape[0], img_rows, img_cols, 1)\n",
    "    \n",
    "    x_data = x_data.astype('float32')\n",
    "    x_data /= 255\n",
    "    return x_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naast de input bekijken we ook eventjes naar de output.\n",
    "We zien dat dit 1 cijfer is, een neuraal netwerk is in staat om een regressie-probleem op te lossen maar heeft het daar vaak lastig mee. Omdat we in dit geval maar 10 exacte cijfers kunnen bekomen kunnen we dit probleem beter vertalen naar een classificatie ipv een regressie. We doen dit door one-hot-encoding toe te passen.\n",
    "\n",
    "one-hot-encoding: Een lijst waarbij ieder element uit de lijst een 0 of een 1 kan zijn. Een 0 element betekend dat de betekenis aan dit element niet waar is, een 1 betekend dat dit wel waar is. Keras heeft hier een eenvoudige util functie voor namelijk utils.to_cateogrical/2.  \n",
    "bv. Het cijfer 5 in de one-hot-encoding in ons probleem wordt weergegeven als [0,0,0,0,0,1,0,0,0,0] (zero-indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_Y_data(y_unpreprared_data):\n",
    "    y_data = utils.to_categorical(y_unpreprared_data, 10)\n",
    "    return y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu dat we weten hoe we onze input en output gaan voorstellen gaan we werkelijk het neuraal netwerk maken. Zoals reeds gezegd zouden er 2 modelen gemaakt worden. Namelijk een DNN en een CNN model.  \n",
    "\n",
    "_De input van het DNN zal ook 2 dimensionaal zijn maar zal beginnen met een Flatten layer die een 2D structuur terug 1D maakt. Dit doen we zodat we dezelfde preprocessing functie kunnen gebruiken voor ons DNN en CNN model_\n",
    "\n",
    "We zullen 2 manieren zien om ons model te definieren.\n",
    "\n",
    "Model 1: Deep neuraal netwerk\n",
    "- Input layer: Flatten\n",
    "    - Input shape: 1x28x28\n",
    "- hidden layer 1: Dense\n",
    "    - nodes: 512\n",
    "    - Activatie functie: Relu\n",
    "- hidden layer 2: Dense\n",
    "    - nodes: 256\n",
    "    - Activatie functie: Relu\n",
    "- hidden layer 3: Dense\n",
    "    - nodes: 128\n",
    "    - Activatie functie: Relu\n",
    "- hidden layer 4: Dense\n",
    "    - nodes: 32\n",
    "    - Activatie functie: Relu\n",
    "- output layer: Dense\n",
    "    - nodes: 10 (de 10 cijfers die te herkennen zijn, 1 output per cijfer)\n",
    "    - Activatie functie: Softmax (Handig voor bepaling van waarschijnlijkheid per output)\n",
    "    - optimizer: Stochastic Gradient descent (gradient descent met momentum)\n",
    "    - loss: categorical crossentropy (Handig als er one-hot encoding is gebeurd voor de output)\n",
    "\n",
    "        \n",
    "Model 2: Convolutioneel neuraal netwerk\n",
    "- Input layer: Conv2D\n",
    "    - Input shape: 1x28x28\n",
    "    - nodes: 32\n",
    "    - kernel_size: 3x3 (Grootte van het convolutie raster) \n",
    "    - Activatie functie: Relu\n",
    "- hidden layer 1: Conv2D\n",
    "    - nodes: 64\n",
    "    - kernel_size: 3x3 (Grootte van het convolutie raster) \n",
    "    - Activatie functie: Relu\n",
    "- hidden layer 2: Flatten\n",
    "- hidden layer 3: Dense\n",
    "    - nodes: 128\n",
    "    - Activatie functie: Relu\n",
    "- hidden layer 4: Dense\n",
    "    - nodes: 128\n",
    "    - Activatie functie: Relu\n",
    "- output layer: Dense\n",
    "    - nodes: 10 (de 10 cijfers die te herkennen zijn, 1 output per cijfer)\n",
    "    - Activatie functie: Softmax (Handig voor bepaling van waarschijnlijkheid per output)\n",
    "    - optimizer: Stochastic Gradient descent (gradient descent met momentum)\n",
    "    - loss: categorical crossentropy (Handig als er one-hot encoding is gebeurd voor de output)\n",
    "    \n",
    "    \n",
    "Een convolutielaag bekijkt beschouwd niet al de input maar bekijkt een klein deel van de input. Op deze manier kan er op zoek gegaan worden naar lokale afhankelijkheden. Dit is handig bijvoorbeeld interessant bij een afbeelding aangezien de uiterst linker boven pixel en de meest rechter onder pixel weinig verband houden met elkaar. Het neuraal netwerk hier in begeleiden mbv een convolutie laag zorgt ervoor dat het netwerk sneller zal trainen. Uit onderzoek is gebleken dat een eerste convolutie laag vaak op zoek gaat naar eenvoudige patronen. (Rechte lijnen in bepaalde richtingen), een 2de laag zal deze eenvoudige patronen vaak combineren tot een iets complex patroon. (een vierkant, een cirkel,..) Verdere convolutie lagen zullen dus steeds complexere patronen kunnen herkennen.\n",
    "\n",
    "In onderstaande afbeelding zie je hoe een convolutie te werk gaat. De grootte van de kernel is bepaald adhv de parameter, de cijfers in de kernel zijn de gewichten die door het netwerk bepaald/gezocht moeten worden. De kernel laat zien naar wat voor soort patronen er op zoek gegaan zal worden.\n",
    "![text alt](img/keras_conv2d.gif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of DNN model\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 570,602\n",
      "Trainable params: 570,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Summary of CNN model\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               4718720   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 4,755,338\n",
      "Trainable params: 4,755,338\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (28,28,1)\n",
    "def create_model_DNN():\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=input_shape))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(loss=losses.categorical_crossentropy,\n",
    "                  optimizer=\"sgd\",\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_model_CNN():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(loss=losses.categorical_crossentropy,\n",
    "                  optimizer=\"sgd\",\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model_dnn = create_model_DNN()\n",
    "model_cnn = create_model_CNN()\n",
    "print(\"Summary of DNN model\")\n",
    "model_dnn.summary()\n",
    "print(\"\")\n",
    "print(\"Summary of CNN model\")\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu dat we onze netwerken hebben gaan we deze netwerken trainen. Initeel zijn de gewichten namelijk willekeurig maar deze moeten getraind worden om een correcte voorspelleing te doen van de output. Dit kan aan de hand van de fit functie waarbij zowel X als Y waardes worden meegegeven. De batch_size parameter bepaald hoeveel voorbeelden er gelijktijdig bekeken worden. Wiskundig gezien bepaald dit de grootte van de matrix die gebruikt wordt voor de berekening. Met de epochs parameter verteld je dat het netwerk al de trainingsdata 12x moet herbekijken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training dnn\n",
      "Train on 60000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 1.4369 - accuracy: 0.6061\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.4231 - accuracy: 0.8845\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3112 - accuracy: 0.9115\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.2652 - accuracy: 0.9239\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.2345 - accuracy: 0.9333\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.2115 - accuracy: 0.9391\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.1916 - accuracy: 0.9456\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1758 - accuracy: 0.9493\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.1622 - accuracy: 0.9537\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.1504 - accuracy: 0.9569\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.1399 - accuracy: 0.9600\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.1313 - accuracy: 0.9621\n",
      "Saving model dnn\n",
      "Finished training model dnn\n",
      "start training cnn\n",
      "Train on 60000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 100s 2ms/sample - loss: 0.6499 - accuracy: 0.8306\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 102s 2ms/sample - loss: 0.2284 - accuracy: 0.9317\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 101s 2ms/sample - loss: 0.1727 - accuracy: 0.9488\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 97s 2ms/sample - loss: 0.1406 - accuracy: 0.9581\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 99s 2ms/sample - loss: 0.1189 - accuracy: 0.9646\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 98s 2ms/sample - loss: 0.1042 - accuracy: 0.9684\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 96s 2ms/sample - loss: 0.0923 - accuracy: 0.9720\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 98s 2ms/sample - loss: 0.0861 - accuracy: 0.9739\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 96s 2ms/sample - loss: 0.0784 - accuracy: 0.9762\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 96s 2ms/sample - loss: 0.0721 - accuracy: 0.9776\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 99s 2ms/sample - loss: 0.0662 - accuracy: 0.9796\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 96s 2ms/sample - loss: 0.0625 - accuracy: 0.9806\n",
      "Saving model cnn\n",
      "Finished training model cnn\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, name):\n",
    "    print(\"start training \" + str(name))\n",
    "    x_prep_train = prepare_X_data(x_unprepared_data=x_train)\n",
    "    y_prep_train = prepare_Y_data(y_unpreprared_data=y_train)\n",
    "    model.fit(x_prep_train, y_prep_train, batch_size=128, epochs=12, verbose=1)\n",
    "    print(\"Saving model \" + str(name))\n",
    "    save_model(model=model, filepath=str(name) + \".h5\")\n",
    "    print(\"Finished training model \" + str(name))\n",
    "    \n",
    "train_model(model_dnn, \"dnn\")\n",
    "print(\"\")\n",
    "train_model(model_cnn, \"cnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na het trainen van het netwerk is het belangrijk om te kijken of het netwerk ook goed werkt voor ongeziene voorbeelden. Het kan namelijk gebeuren dat het netwerk te vaak naar de trainingsdata kijkt met als gevolgd dat het niet goed veralgemeend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model dnn\n",
      "loss: 0.13506913812048732\n",
      "accuracy: 0.9591\n",
      "\n",
      "Model cnn\n",
      "loss: 0.07701360287913121\n",
      "accuracy: 0.9764\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_model(model, name):\n",
    "    x_prep_test = prepare_X_data(x_unprepared_data=x_test)\n",
    "    y_prep_test = prepare_Y_data(y_unpreprared_data=y_test)\n",
    "    result =  model.evaluate(x_prep_test, y_prep_test, verbose=0)\n",
    "    print(\"Model \" + str(name))\n",
    "    print(\"loss: \" + str(result[0]))\n",
    "    print(\"accuracy: \" + str(result[1]))\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "test_model(model_dnn, \"dnn\")\n",
    "test_model(model_cnn, \"cnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tot slot bekijken we even concreet de output van het netwerk en hoe de output vertaald moet worden naar het probleem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dit item zal eerst moeten worden preprocessed volgens de zelfde voorwaarden als de trainingdata zodat we dit aan het neuraal netwerk kunnen geven.\n",
    "\n",
    "Vervolgens laten we het model een voorspelling doen en krijgen we een lijst van 10 elementen terug. De waarde van ieder element in de lijst zegt hoe waarschijnlijk dat dit cijfer het correcte antwoord is. We moeten dus op zoek gaan naar de plaats van het grootste element, dit is de voorspelling van het netwerk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model DNN\n",
      "Prediction array: [1.4471593e-07 1.1726588e-05 9.9725926e-01 2.7110099e-03 2.4664981e-08\n",
      " 3.6646688e-09 5.0601344e-08 5.8049491e-06 1.1968062e-05 5.0615533e-08]\n",
      "Prediction: 2\n",
      "Ground truth: 2\n",
      "\n",
      "Model CNN\n",
      "Prediction array: [2.1972377e-10 7.4975377e-09 9.9994600e-01 8.9790656e-06 1.2777449e-09\n",
      " 1.6411835e-08 8.3682106e-12 2.7591792e-05 1.7446775e-05 4.0198227e-09]\n",
      "Prediction: 2\n",
      "Ground truth: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def predict(model, x_item, y_test = None):\n",
    "    X = prepare_X_data(x_unprepared_data=np.array([x_item]))\n",
    "    prediction = model.predict(X)\n",
    "    print(\"Prediction array: \" + str(prediction[0]))\n",
    "    print(\"Prediction: \" + str(np.argmax(prediction)))\n",
    "    if y_test is not None:\n",
    "        print(\"Ground truth: \" + str(y_test))\n",
    "        print(\"\")\n",
    "    \n",
    "show_img(x_item)\n",
    "print(\"Model DNN\")\n",
    "predict(model_dnn, x_item, y_item)\n",
    "print(\"Model CNN\")\n",
    "predict(model_cnn, x_item, y_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Er is ook een methode voorzien om meerdere, eventueel random geselecteerde, items te voorspellen. Zoals te zien in de code kunnen er meerdere inputs gelijktijdig aan het netwerk worden gegeven zodat de berekening opnieuw gedaan kan worden als een matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction array: [1.7604547e-05 4.0810901e-06 1.6783097e-05 1.1855512e-04 2.7889939e-02\n",
      " 3.2263694e-04 2.5438665e-06 9.0707161e-02 6.2763441e-04 8.8029295e-01]\n",
      "Prediction: 9\n",
      "Ground truth: 9\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction array: [5.10145277e-08 9.98164475e-01 1.71866865e-04 7.58919632e-04\n",
      " 1.19777207e-04 1.06858155e-04 3.71179849e-05 4.80888411e-04\n",
      " 1.21478624e-04 3.87126856e-05]\n",
      "Prediction: 1\n",
      "Ground truth: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def random_predict(model, nb_of_items, x, y = None):\n",
    "    indexes = np.random.choice(range(len(x)), nb_of_items)\n",
    "    X_items = x[indexes]\n",
    "    Y_items = y[indexes]\n",
    "    \n",
    "    X = prepare_X_data(x_unprepared_data=np.array(X_items))\n",
    "    prediction = model.predict(X)\n",
    "    for i in range(nb_of_items):\n",
    "        show_img(X_items[i])\n",
    "        print(\"Prediction array: \" + str(prediction[i]))\n",
    "        print(\"Prediction: \" + str(np.argmax(prediction[i])))\n",
    "        if y is not None:\n",
    "            print(\"Ground truth: \" + str(Y_items[i]))\n",
    "            print(\"\")\n",
    "            \n",
    "random_predict(model_dnn, 2, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tot slot zullen we nog eens een netwerk opslaan en terug opladen. We printen te summary nog een keer zodat duidelijk te zien is dat het CNN netwerk is opgeslagen. Ook kunnen we de predictie voor het opslaan en na het opslaan met elkaar vergelijken en zien we dat de resultaten exact het zelfde zijn. We zijn dus zeker dat dit over het zelfde netwerk gaat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction array: [2.1972377e-10 7.4975377e-09 9.9994600e-01 8.9790656e-06 1.2777449e-09\n",
      " 1.6411835e-08 8.3682106e-12 2.7591792e-05 1.7446775e-05 4.0198227e-09]\n",
      "Prediction: 2\n",
      "Ground truth: 2\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               4718720   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 4,755,338\n",
      "Trainable params: 4,755,338\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Prediction array: [2.1972377e-10 7.4975377e-09 9.9994600e-01 8.9790656e-06 1.2777449e-09\n",
      " 1.6411835e-08 8.3682106e-12 2.7591792e-05 1.7446775e-05 4.0198227e-09]\n",
      "Prediction: 2\n",
      "Ground truth: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict(model_cnn, x_item, y_item)\n",
    "\n",
    "save_model(model=model_cnn, filepath=\"example.h5\")\n",
    "model = load_model(\"example.h5\")\n",
    "model.summary()\n",
    "\n",
    "predict(model, x_item, y_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural_network_env",
   "language": "python",
   "name": "neural_network_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
